{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on https://medium.com/@awjuliani/simple-reinforcement-learning-with-tensorflow-part-4-deep-q-networks-and-beyond-8438a3e2b8df#.rvpnvy5gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-03 01:13:18,704] Making new env: Asterix-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Asterix-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Qnetwork():\n",
    "    def __init__(self, input_size, actions_size):\n",
    "        #The network recieves a frame from the game, flattened into an array.\n",
    "        #It then resizes it and processes it through four convolutional layers.\n",
    "        self.scalarInput =  tf.placeholder(shape=[None,input_size[0] * input_size[1] * input_size[2]],dtype=tf.float32)\n",
    "        self.imageIn = tf.reshape(self.scalarInput,shape=[-1,input_size[0],input_size[1],input_size[2]])\n",
    "        self.conv1 = tf.contrib.layers.convolution2d( \\\n",
    "            inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
    "        self.conv2 = tf.contrib.layers.convolution2d( \\\n",
    "            inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
    "        self.conv3 = tf.contrib.layers.convolution2d( \\\n",
    "            inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        self.conv4 = tf.contrib.layers.convolution2d( \\\n",
    "            inputs=self.conv3,num_outputs=512,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
    "        \n",
    "        conv4_shape = self.conv4.get_shape().as_list()\n",
    "        #We take the output from the final convolutional layer and split it into separate advantage and value streams.\n",
    "        self.streamAC, self.streamVC = tf.split(3,2,self.conv4)\n",
    "        self.streamA = tf.contrib.layers.flatten(self.streamAC)\n",
    "        self.streamV = tf.contrib.layers.flatten(self.streamVC)\n",
    "        self.AW = tf.Variable(tf.random_normal([conv4_shape[1]*conv4_shape[2]*conv4_shape[3]//2, actions_size]))\n",
    "        self.VW = tf.Variable(tf.random_normal([conv4_shape[1]*conv4_shape[2]*conv4_shape[3]//2, 1]))\n",
    "        self.Advantage = tf.matmul(self.streamA,self.AW)\n",
    "        self.Value = tf.matmul(self.streamV,self.VW)\n",
    "        \n",
    "        #Then combine them together to get our final Q-values.\n",
    "        self.Qout = self.Value + tf.sub(self.Advantage,tf.reduce_mean(self.Advantage,reduction_indices=1,keep_dims=True))\n",
    "        self.predict = tf.argmax(self.Qout, 1)\n",
    "        \n",
    "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
    "        self.actions_onehot = tf.one_hot(self.actions, actions_size,dtype=tf.float32)\n",
    "        \n",
    "        self.Q = tf.reduce_sum(tf.mul(self.Qout, self.actions_onehot), reduction_indices=1)\n",
    "        \n",
    "        self.td_error = tf.square(self.targetQ - self.Q)\n",
    "        self.loss = tf.reduce_mean(self.td_error)\n",
    "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        self.updateModel = self.trainer.minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class experience_buffer():\n",
    "    def __init__(self, buffer_size = 50000):\n",
    "        self.buffer = []\n",
    "        self.buffer_size = buffer_size\n",
    "    \n",
    "    def add(self, experience):\n",
    "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
    "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
    "        self.buffer.extend(experience)\n",
    "            \n",
    "    def sample(self, size):\n",
    "        return np.reshape(np.array(random.sample(self.buffer, size)), [size, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processState(states, input_size):\n",
    "    return np.reshape(states,[input_size[0] * input_size[1] * input_size[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def updateTargetGraph(tfVars, tau):\n",
    "    total_vars = len(tfVars)\n",
    "    op_holder = []\n",
    "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
    "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
    "    return op_holder\n",
    "\n",
    "def updateTarget(op_holder,sess):\n",
    "    for op in op_holder:\n",
    "        sess.run(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32 #How many experiences to use for each training step.\n",
    "update_freq = 4 #How often to perform a training step.\n",
    "y = .99 #Discount factor on the target Q-values\n",
    "startE = 1 #Starting chance of random action\n",
    "endE = 0.1 #Final chance of random action\n",
    "anneling_steps = 10000. #How many steps of training to reduce startE to endE.\n",
    "num_episodes = 10000 #How many episodes of game environment to train network with.\n",
    "pre_train_steps = 10000 #How many steps of random actions before training begins.\n",
    "max_epLength = 50 #The max allowed length of our episode.\n",
    "load_model = False #Whether to load a saved model.\n",
    "path = \"./dqn\" #The path to save our model to.\n",
    "tau = 0.001 #Rate to update target network toward primary network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = env.observation_space.shape\n",
    "actions_size = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-70-eee0c5ea0656>:5 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-03 01:36:50,215] From <ipython-input-70-eee0c5ea0656>:5 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Model\n",
      "500 120.0 1\n",
      "1000 115.0 1\n",
      "1500 115.0 1\n",
      "2000 130.0 1\n",
      "2500 130.0 1\n",
      "3000 95.0 1\n",
      "3500 135.0 1\n",
      "4000 120.0 1\n",
      "4500 125.0 1\n",
      "5000 105.0 1\n",
      "5500 125.0 1\n",
      "6000 130.0 1\n",
      "6500 115.0 1\n",
      "7000 130.0 1\n",
      "7500 120.0 1\n",
      "8000 120.0 1\n",
      "8500 110.0 1\n",
      "9000 105.0 1\n",
      "9500 100.0 1\n",
      "10000 105.0 1\n",
      "10500 125.0 0.9549999999999828\n",
      "11000 145.0 0.9099999999999655\n",
      "11500 110.0 0.8649999999999483\n",
      "12000 100.0 0.819999999999931\n",
      "12500 110.0 0.7749999999999138\n",
      "13000 110.0 0.7299999999998965\n",
      "13500 115.0 0.6849999999998793\n",
      "14000 100.0 0.639999999999862\n",
      "14500 150.0 0.5949999999998448\n",
      "15000 120.0 0.5499999999998275\n",
      "15500 95.0 0.5049999999998103\n",
      "16000 125.0 0.4599999999998177\n",
      "16500 140.0 0.41499999999982823\n",
      "17000 115.0 0.36999999999983874\n",
      "17500 115.0 0.32499999999984924\n",
      "18000 110.0 0.27999999999985975\n",
      "18500 150.0 0.23499999999986562\n",
      "19000 95.0 0.18999999999986225\n",
      "19500 110.0 0.14499999999985888\n",
      "20000 115.0 0.09999999999985551\n",
      "20500 105.0 0.09999999999985551\n",
      "21000 130.0 0.09999999999985551\n",
      "21500 150.0 0.09999999999985551\n",
      "22000 115.0 0.09999999999985551\n",
      "22500 95.0 0.09999999999985551\n",
      "23000 165.0 0.09999999999985551\n",
      "23500 140.0 0.09999999999985551\n",
      "24000 115.0 0.09999999999985551\n",
      "24500 110.0 0.09999999999985551\n",
      "25000 130.0 0.09999999999985551\n",
      "25500 120.0 0.09999999999985551\n",
      "26000 135.0 0.09999999999985551\n",
      "26500 110.0 0.09999999999985551\n",
      "27000 95.0 0.09999999999985551\n",
      "27500 115.0 0.09999999999985551\n",
      "28000 110.0 0.09999999999985551\n",
      "28500 120.0 0.09999999999985551\n",
      "29000 110.0 0.09999999999985551\n",
      "29500 110.0 0.09999999999985551\n",
      "30000 120.0 0.09999999999985551\n",
      "30500 100.0 0.09999999999985551\n",
      "31000 110.0 0.09999999999985551\n",
      "31500 110.0 0.09999999999985551\n",
      "32000 105.0 0.09999999999985551\n",
      "32500 125.0 0.09999999999985551\n",
      "33000 115.0 0.09999999999985551\n",
      "33500 90.0 0.09999999999985551\n",
      "34000 125.0 0.09999999999985551\n",
      "34500 115.0 0.09999999999985551\n",
      "35000 135.0 0.09999999999985551\n",
      "35500 100.0 0.09999999999985551\n",
      "36000 125.0 0.09999999999985551\n",
      "36500 95.0 0.09999999999985551\n",
      "37000 110.0 0.09999999999985551\n",
      "37500 120.0 0.09999999999985551\n",
      "38000 155.0 0.09999999999985551\n",
      "38500 115.0 0.09999999999985551\n",
      "39000 145.0 0.09999999999985551\n",
      "39500 110.0 0.09999999999985551\n",
      "40000 120.0 0.09999999999985551\n",
      "40500 175.0 0.09999999999985551\n",
      "41000 155.0 0.09999999999985551\n",
      "41500 110.0 0.09999999999985551\n",
      "42000 150.0 0.09999999999985551\n",
      "42500 125.0 0.09999999999985551\n",
      "43000 155.0 0.09999999999985551\n",
      "43500 150.0 0.09999999999985551\n",
      "44000 140.0 0.09999999999985551\n",
      "44500 180.0 0.09999999999985551\n",
      "45000 155.0 0.09999999999985551\n",
      "45500 170.0 0.09999999999985551\n",
      "46000 150.0 0.09999999999985551\n",
      "46500 140.0 0.09999999999985551\n",
      "47000 130.0 0.09999999999985551\n",
      "47500 130.0 0.09999999999985551\n",
      "48000 155.0 0.09999999999985551\n",
      "48500 170.0 0.09999999999985551\n",
      "49000 165.0 0.09999999999985551\n",
      "49500 135.0 0.09999999999985551\n",
      "50000 150.0 0.09999999999985551\n",
      "Saved Model\n",
      "50500 170.0 0.09999999999985551\n",
      "51000 165.0 0.09999999999985551\n",
      "51500 130.0 0.09999999999985551\n",
      "52000 180.0 0.09999999999985551\n",
      "52500 140.0 0.09999999999985551\n",
      "53000 180.0 0.09999999999985551\n",
      "53500 185.0 0.09999999999985551\n",
      "54000 170.0 0.09999999999985551\n",
      "54500 185.0 0.09999999999985551\n",
      "55000 190.0 0.09999999999985551\n",
      "55500 160.0 0.09999999999985551\n",
      "56000 160.0 0.09999999999985551\n",
      "56500 175.0 0.09999999999985551\n",
      "57000 195.0 0.09999999999985551\n",
      "57500 180.0 0.09999999999985551\n",
      "58000 160.0 0.09999999999985551\n",
      "58500 195.0 0.09999999999985551\n",
      "59000 200.0 0.09999999999985551\n",
      "59500 180.0 0.09999999999985551\n",
      "60000 200.0 0.09999999999985551\n",
      "60500 150.0 0.09999999999985551\n",
      "61000 205.0 0.09999999999985551\n",
      "61500 180.0 0.09999999999985551\n",
      "62000 185.0 0.09999999999985551\n",
      "62500 175.0 0.09999999999985551\n",
      "63000 190.0 0.09999999999985551\n",
      "63500 205.0 0.09999999999985551\n",
      "64000 200.0 0.09999999999985551\n",
      "64500 185.0 0.09999999999985551\n",
      "65000 175.0 0.09999999999985551\n",
      "65500 215.0 0.09999999999985551\n",
      "66000 195.0 0.09999999999985551\n",
      "66500 200.0 0.09999999999985551\n",
      "67000 185.0 0.09999999999985551\n",
      "67500 210.0 0.09999999999985551\n",
      "68000 195.0 0.09999999999985551\n",
      "68500 200.0 0.09999999999985551\n",
      "69000 210.0 0.09999999999985551\n",
      "69500 215.0 0.09999999999985551\n",
      "70000 210.0 0.09999999999985551\n",
      "70500 200.0 0.09999999999985551\n",
      "71000 190.0 0.09999999999985551\n",
      "71500 230.0 0.09999999999985551\n",
      "72000 225.0 0.09999999999985551\n",
      "72500 225.0 0.09999999999985551\n",
      "73000 230.0 0.09999999999985551\n",
      "73500 230.0 0.09999999999985551\n",
      "74000 235.0 0.09999999999985551\n",
      "74500 245.0 0.09999999999985551\n",
      "75000 230.0 0.09999999999985551\n",
      "75500 230.0 0.09999999999985551\n",
      "76000 220.0 0.09999999999985551\n",
      "76500 225.0 0.09999999999985551\n",
      "77000 245.0 0.09999999999985551\n",
      "77500 255.0 0.09999999999985551\n",
      "78000 270.0 0.09999999999985551\n",
      "78500 245.0 0.09999999999985551\n",
      "79000 250.0 0.09999999999985551\n",
      "79500 250.0 0.09999999999985551\n",
      "80000 260.0 0.09999999999985551\n",
      "80500 240.0 0.09999999999985551\n",
      "81000 260.0 0.09999999999985551\n",
      "81500 280.0 0.09999999999985551\n",
      "82000 250.0 0.09999999999985551\n",
      "82500 260.0 0.09999999999985551\n",
      "83000 265.0 0.09999999999985551\n",
      "83500 275.0 0.09999999999985551\n",
      "84000 260.0 0.09999999999985551\n",
      "84500 290.0 0.09999999999985551\n",
      "85000 250.0 0.09999999999985551\n",
      "85500 270.0 0.09999999999985551\n",
      "86000 275.0 0.09999999999985551\n",
      "86500 295.0 0.09999999999985551\n",
      "87000 285.0 0.09999999999985551\n",
      "87500 305.0 0.09999999999985551\n",
      "88000 275.0 0.09999999999985551\n",
      "88500 285.0 0.09999999999985551\n",
      "89000 280.0 0.09999999999985551\n",
      "89500 290.0 0.09999999999985551\n",
      "90000 280.0 0.09999999999985551\n",
      "90500 300.0 0.09999999999985551\n",
      "91000 295.0 0.09999999999985551\n",
      "91500 295.0 0.09999999999985551\n",
      "92000 295.0 0.09999999999985551\n",
      "92500 300.0 0.09999999999985551\n",
      "93000 295.0 0.09999999999985551\n",
      "93500 290.0 0.09999999999985551\n",
      "94000 300.0 0.09999999999985551\n",
      "94500 295.0 0.09999999999985551\n",
      "95000 330.0 0.09999999999985551\n",
      "95500 280.0 0.09999999999985551\n",
      "96000 290.0 0.09999999999985551\n",
      "96500 325.0 0.09999999999985551\n",
      "97000 315.0 0.09999999999985551\n",
      "97500 330.0 0.09999999999985551\n",
      "98000 295.0 0.09999999999985551\n",
      "98500 325.0 0.09999999999985551\n",
      "99000 315.0 0.09999999999985551\n",
      "99500 325.0 0.09999999999985551\n",
      "100000 320.0 0.09999999999985551\n",
      "Saved Model\n",
      "100500 300.0 0.09999999999985551\n",
      "101000 300.0 0.09999999999985551\n",
      "101500 320.0 0.09999999999985551\n",
      "102000 330.0 0.09999999999985551\n",
      "102500 330.0 0.09999999999985551\n",
      "103000 335.0 0.09999999999985551\n",
      "103500 340.0 0.09999999999985551\n",
      "104000 350.0 0.09999999999985551\n",
      "104500 310.0 0.09999999999985551\n",
      "105000 320.0 0.09999999999985551\n",
      "105500 345.0 0.09999999999985551\n",
      "106000 345.0 0.09999999999985551\n",
      "106500 310.0 0.09999999999985551\n",
      "107000 310.0 0.09999999999985551\n",
      "107500 340.0 0.09999999999985551\n",
      "108000 355.0 0.09999999999985551\n",
      "108500 355.0 0.09999999999985551\n",
      "109000 335.0 0.09999999999985551\n",
      "109500 345.0 0.09999999999985551\n",
      "110000 355.0 0.09999999999985551\n",
      "110500 340.0 0.09999999999985551\n",
      "111000 340.0 0.09999999999985551\n",
      "111500 365.0 0.09999999999985551\n",
      "112000 350.0 0.09999999999985551\n",
      "112500 345.0 0.09999999999985551\n",
      "113000 360.0 0.09999999999985551\n",
      "113500 380.0 0.09999999999985551\n",
      "114000 365.0 0.09999999999985551\n",
      "114500 335.0 0.09999999999985551\n",
      "115000 370.0 0.09999999999985551\n",
      "115500 380.0 0.09999999999985551\n",
      "116000 365.0 0.09999999999985551\n",
      "116500 350.0 0.09999999999985551\n",
      "117000 375.0 0.09999999999985551\n",
      "117500 385.0 0.09999999999985551\n",
      "118000 365.0 0.09999999999985551\n",
      "118500 355.0 0.09999999999985551\n",
      "119000 365.0 0.09999999999985551\n",
      "119500 370.0 0.09999999999985551\n",
      "120000 325.0 0.09999999999985551\n",
      "120500 385.0 0.09999999999985551\n",
      "121000 350.0 0.09999999999985551\n",
      "121500 370.0 0.09999999999985551\n",
      "122000 355.0 0.09999999999985551\n",
      "122500 365.0 0.09999999999985551\n",
      "123000 390.0 0.09999999999985551\n",
      "123500 365.0 0.09999999999985551\n",
      "124000 375.0 0.09999999999985551\n",
      "124500 370.0 0.09999999999985551\n",
      "125000 370.0 0.09999999999985551\n",
      "125500 370.0 0.09999999999985551\n",
      "126000 385.0 0.09999999999985551\n",
      "126500 355.0 0.09999999999985551\n",
      "127000 385.0 0.09999999999985551\n",
      "127500 365.0 0.09999999999985551\n",
      "128000 390.0 0.09999999999985551\n",
      "128500 375.0 0.09999999999985551\n",
      "129000 390.0 0.09999999999985551\n",
      "129500 365.0 0.09999999999985551\n",
      "130000 365.0 0.09999999999985551\n",
      "130500 350.0 0.09999999999985551\n",
      "131000 395.0 0.09999999999985551\n",
      "131500 390.0 0.09999999999985551\n",
      "132000 365.0 0.09999999999985551\n",
      "132500 385.0 0.09999999999985551\n",
      "133000 400.0 0.09999999999985551\n",
      "133500 380.0 0.09999999999985551\n",
      "134000 385.0 0.09999999999985551\n",
      "134500 375.0 0.09999999999985551\n",
      "135000 380.0 0.09999999999985551\n",
      "135500 395.0 0.09999999999985551\n",
      "136000 390.0 0.09999999999985551\n",
      "136500 385.0 0.09999999999985551\n",
      "137000 380.0 0.09999999999985551\n",
      "137500 385.0 0.09999999999985551\n",
      "138000 385.0 0.09999999999985551\n",
      "138500 395.0 0.09999999999985551\n",
      "139000 385.0 0.09999999999985551\n",
      "139500 385.0 0.09999999999985551\n",
      "140000 365.0 0.09999999999985551\n",
      "140500 400.0 0.09999999999985551\n",
      "141000 390.0 0.09999999999985551\n",
      "141500 385.0 0.09999999999985551\n",
      "142000 365.0 0.09999999999985551\n",
      "142500 395.0 0.09999999999985551\n",
      "143000 400.0 0.09999999999985551\n",
      "143500 400.0 0.09999999999985551\n",
      "144000 400.0 0.09999999999985551\n",
      "144500 400.0 0.09999999999985551\n",
      "145000 385.0 0.09999999999985551\n",
      "145500 395.0 0.09999999999985551\n",
      "146000 390.0 0.09999999999985551\n",
      "146500 400.0 0.09999999999985551\n",
      "147000 390.0 0.09999999999985551\n",
      "147500 395.0 0.09999999999985551\n",
      "148000 375.0 0.09999999999985551\n",
      "148500 370.0 0.09999999999985551\n",
      "149000 380.0 0.09999999999985551\n",
      "149500 400.0 0.09999999999985551\n",
      "150000 400.0 0.09999999999985551\n",
      "Saved Model\n",
      "150500 395.0 0.09999999999985551\n",
      "151000 385.0 0.09999999999985551\n",
      "151500 395.0 0.09999999999985551\n",
      "152000 390.0 0.09999999999985551\n",
      "152500 395.0 0.09999999999985551\n",
      "153000 395.0 0.09999999999985551\n",
      "153500 395.0 0.09999999999985551\n",
      "154000 390.0 0.09999999999985551\n",
      "154500 390.0 0.09999999999985551\n",
      "155000 385.0 0.09999999999985551\n",
      "155500 395.0 0.09999999999985551\n",
      "156000 395.0 0.09999999999985551\n",
      "156500 400.0 0.09999999999985551\n",
      "157000 390.0 0.09999999999985551\n",
      "157500 370.0 0.09999999999985551\n",
      "158000 395.0 0.09999999999985551\n",
      "158500 375.0 0.09999999999985551\n",
      "159000 400.0 0.09999999999985551\n",
      "159500 390.0 0.09999999999985551\n",
      "160000 385.0 0.09999999999985551\n",
      "160500 400.0 0.09999999999985551\n",
      "161000 400.0 0.09999999999985551\n",
      "161500 395.0 0.09999999999985551\n",
      "162000 400.0 0.09999999999985551\n",
      "162500 400.0 0.09999999999985551\n",
      "163000 400.0 0.09999999999985551\n",
      "163500 385.0 0.09999999999985551\n",
      "164000 395.0 0.09999999999985551\n",
      "164500 390.0 0.09999999999985551\n",
      "165000 385.0 0.09999999999985551\n",
      "165500 385.0 0.09999999999985551\n",
      "166000 395.0 0.09999999999985551\n",
      "166500 395.0 0.09999999999985551\n",
      "167000 390.0 0.09999999999985551\n",
      "167500 385.0 0.09999999999985551\n",
      "168000 380.0 0.09999999999985551\n",
      "168500 385.0 0.09999999999985551\n",
      "169000 395.0 0.09999999999985551\n",
      "169500 400.0 0.09999999999985551\n",
      "170000 385.0 0.09999999999985551\n",
      "170500 390.0 0.09999999999985551\n",
      "171000 400.0 0.09999999999985551\n",
      "171500 400.0 0.09999999999985551\n",
      "172000 380.0 0.09999999999985551\n",
      "172500 380.0 0.09999999999985551\n",
      "173000 395.0 0.09999999999985551\n",
      "173500 385.0 0.09999999999985551\n",
      "174000 400.0 0.09999999999985551\n",
      "174500 395.0 0.09999999999985551\n",
      "175000 390.0 0.09999999999985551\n",
      "175500 385.0 0.09999999999985551\n",
      "176000 395.0 0.09999999999985551\n",
      "176500 395.0 0.09999999999985551\n",
      "177000 395.0 0.09999999999985551\n",
      "177500 400.0 0.09999999999985551\n",
      "178000 395.0 0.09999999999985551\n",
      "178500 400.0 0.09999999999985551\n",
      "179000 400.0 0.09999999999985551\n",
      "179500 400.0 0.09999999999985551\n",
      "180000 400.0 0.09999999999985551\n",
      "180500 385.0 0.09999999999985551\n",
      "181000 400.0 0.09999999999985551\n",
      "181500 400.0 0.09999999999985551\n",
      "182000 400.0 0.09999999999985551\n",
      "182500 385.0 0.09999999999985551\n",
      "183000 395.0 0.09999999999985551\n",
      "183500 395.0 0.09999999999985551\n",
      "184000 395.0 0.09999999999985551\n",
      "184500 395.0 0.09999999999985551\n",
      "185000 400.0 0.09999999999985551\n",
      "185500 400.0 0.09999999999985551\n",
      "186000 385.0 0.09999999999985551\n",
      "186500 400.0 0.09999999999985551\n",
      "187000 395.0 0.09999999999985551\n",
      "187500 390.0 0.09999999999985551\n",
      "188000 380.0 0.09999999999985551\n",
      "188500 395.0 0.09999999999985551\n",
      "189000 395.0 0.09999999999985551\n",
      "189500 400.0 0.09999999999985551\n",
      "190000 375.0 0.09999999999985551\n",
      "190500 365.0 0.09999999999985551\n",
      "191000 395.0 0.09999999999985551\n",
      "191500 390.0 0.09999999999985551\n",
      "192000 365.0 0.09999999999985551\n",
      "192500 385.0 0.09999999999985551\n",
      "193000 400.0 0.09999999999985551\n",
      "193500 380.0 0.09999999999985551\n",
      "194000 390.0 0.09999999999985551\n",
      "194500 385.0 0.09999999999985551\n",
      "195000 395.0 0.09999999999985551\n",
      "195500 390.0 0.09999999999985551\n",
      "196000 385.0 0.09999999999985551\n",
      "196500 375.0 0.09999999999985551\n",
      "197000 395.0 0.09999999999985551\n",
      "197500 400.0 0.09999999999985551\n",
      "198000 395.0 0.09999999999985551\n",
      "198500 390.0 0.09999999999985551\n",
      "199000 375.0 0.09999999999985551\n",
      "199500 385.0 0.09999999999985551\n",
      "200000 390.0 0.09999999999985551\n",
      "Saved Model\n",
      "200500 400.0 0.09999999999985551\n",
      "201000 385.0 0.09999999999985551\n",
      "201500 400.0 0.09999999999985551\n",
      "202000 390.0 0.09999999999985551\n",
      "202500 395.0 0.09999999999985551\n",
      "203000 385.0 0.09999999999985551\n",
      "203500 395.0 0.09999999999985551\n",
      "204000 370.0 0.09999999999985551\n",
      "204500 380.0 0.09999999999985551\n",
      "205000 395.0 0.09999999999985551\n",
      "205500 395.0 0.09999999999985551\n",
      "206000 400.0 0.09999999999985551\n",
      "206500 385.0 0.09999999999985551\n",
      "207000 380.0 0.09999999999985551\n",
      "207500 400.0 0.09999999999985551\n",
      "208000 390.0 0.09999999999985551\n",
      "208500 395.0 0.09999999999985551\n",
      "209000 400.0 0.09999999999985551\n",
      "209500 395.0 0.09999999999985551\n",
      "210000 385.0 0.09999999999985551\n",
      "210500 390.0 0.09999999999985551\n",
      "211000 385.0 0.09999999999985551\n",
      "211500 395.0 0.09999999999985551\n",
      "212000 400.0 0.09999999999985551\n",
      "212500 360.0 0.09999999999985551\n",
      "213000 400.0 0.09999999999985551\n",
      "213500 395.0 0.09999999999985551\n",
      "214000 390.0 0.09999999999985551\n",
      "214500 390.0 0.09999999999985551\n",
      "215000 395.0 0.09999999999985551\n",
      "215500 395.0 0.09999999999985551\n",
      "216000 380.0 0.09999999999985551\n",
      "216500 395.0 0.09999999999985551\n",
      "217000 395.0 0.09999999999985551\n",
      "217500 400.0 0.09999999999985551\n",
      "218000 390.0 0.09999999999985551\n",
      "218500 400.0 0.09999999999985551\n",
      "219000 390.0 0.09999999999985551\n",
      "219500 400.0 0.09999999999985551\n",
      "220000 395.0 0.09999999999985551\n",
      "220500 390.0 0.09999999999985551\n",
      "221000 385.0 0.09999999999985551\n",
      "221500 390.0 0.09999999999985551\n",
      "222000 365.0 0.09999999999985551\n",
      "222500 395.0 0.09999999999985551\n",
      "223000 400.0 0.09999999999985551\n",
      "223500 400.0 0.09999999999985551\n",
      "224000 395.0 0.09999999999985551\n",
      "224500 395.0 0.09999999999985551\n",
      "225000 400.0 0.09999999999985551\n",
      "225500 390.0 0.09999999999985551\n",
      "226000 390.0 0.09999999999985551\n",
      "226500 400.0 0.09999999999985551\n",
      "227000 370.0 0.09999999999985551\n",
      "227500 395.0 0.09999999999985551\n",
      "228000 395.0 0.09999999999985551\n",
      "228500 395.0 0.09999999999985551\n",
      "229000 375.0 0.09999999999985551\n",
      "229500 400.0 0.09999999999985551\n",
      "230000 395.0 0.09999999999985551\n",
      "230500 375.0 0.09999999999985551\n",
      "231000 400.0 0.09999999999985551\n",
      "231500 400.0 0.09999999999985551\n",
      "232000 395.0 0.09999999999985551\n",
      "232500 400.0 0.09999999999985551\n",
      "233000 400.0 0.09999999999985551\n",
      "233500 390.0 0.09999999999985551\n",
      "234000 400.0 0.09999999999985551\n",
      "234500 400.0 0.09999999999985551\n",
      "235000 385.0 0.09999999999985551\n",
      "235500 400.0 0.09999999999985551\n",
      "236000 390.0 0.09999999999985551\n",
      "236500 390.0 0.09999999999985551\n",
      "237000 390.0 0.09999999999985551\n",
      "237500 400.0 0.09999999999985551\n",
      "238000 395.0 0.09999999999985551\n",
      "238500 395.0 0.09999999999985551\n",
      "239000 395.0 0.09999999999985551\n",
      "239500 380.0 0.09999999999985551\n",
      "240000 375.0 0.09999999999985551\n",
      "240500 400.0 0.09999999999985551\n",
      "241000 400.0 0.09999999999985551\n",
      "241500 400.0 0.09999999999985551\n",
      "242000 390.0 0.09999999999985551\n",
      "242500 370.0 0.09999999999985551\n",
      "243000 385.0 0.09999999999985551\n",
      "243500 395.0 0.09999999999985551\n",
      "244000 395.0 0.09999999999985551\n",
      "244500 395.0 0.09999999999985551\n",
      "245000 375.0 0.09999999999985551\n",
      "245500 345.0 0.09999999999985551\n",
      "246000 385.0 0.09999999999985551\n",
      "246500 400.0 0.09999999999985551\n",
      "247000 400.0 0.09999999999985551\n",
      "247500 395.0 0.09999999999985551\n",
      "248000 350.0 0.09999999999985551\n",
      "248500 390.0 0.09999999999985551\n",
      "249000 390.0 0.09999999999985551\n",
      "249500 400.0 0.09999999999985551\n",
      "250000 395.0 0.09999999999985551\n",
      "Saved Model\n",
      "250500 400.0 0.09999999999985551\n",
      "251000 390.0 0.09999999999985551\n",
      "251500 390.0 0.09999999999985551\n",
      "252000 395.0 0.09999999999985551\n",
      "252500 395.0 0.09999999999985551\n",
      "253000 395.0 0.09999999999985551\n",
      "253500 355.0 0.09999999999985551\n",
      "254000 395.0 0.09999999999985551\n",
      "254500 400.0 0.09999999999985551\n",
      "255000 390.0 0.09999999999985551\n",
      "255500 375.0 0.09999999999985551\n",
      "256000 395.0 0.09999999999985551\n",
      "256500 390.0 0.09999999999985551\n",
      "257000 395.0 0.09999999999985551\n",
      "257500 400.0 0.09999999999985551\n",
      "258000 390.0 0.09999999999985551\n",
      "258500 385.0 0.09999999999985551\n",
      "259000 390.0 0.09999999999985551\n",
      "259500 380.0 0.09999999999985551\n",
      "260000 380.0 0.09999999999985551\n",
      "260500 390.0 0.09999999999985551\n",
      "261000 375.0 0.09999999999985551\n",
      "261500 390.0 0.09999999999985551\n",
      "262000 395.0 0.09999999999985551\n",
      "262500 320.0 0.09999999999985551\n",
      "263000 385.0 0.09999999999985551\n",
      "263500 375.0 0.09999999999985551\n",
      "264000 395.0 0.09999999999985551\n",
      "264500 400.0 0.09999999999985551\n",
      "265000 395.0 0.09999999999985551\n",
      "265500 390.0 0.09999999999985551\n",
      "266000 395.0 0.09999999999985551\n",
      "266500 390.0 0.09999999999985551\n",
      "267000 385.0 0.09999999999985551\n",
      "267500 390.0 0.09999999999985551\n",
      "268000 390.0 0.09999999999985551\n",
      "268500 395.0 0.09999999999985551\n",
      "269000 395.0 0.09999999999985551\n",
      "269500 395.0 0.09999999999985551\n",
      "270000 390.0 0.09999999999985551\n",
      "270500 400.0 0.09999999999985551\n",
      "271000 400.0 0.09999999999985551\n",
      "271500 390.0 0.09999999999985551\n",
      "272000 390.0 0.09999999999985551\n",
      "272500 395.0 0.09999999999985551\n",
      "273000 390.0 0.09999999999985551\n",
      "273500 375.0 0.09999999999985551\n",
      "274000 385.0 0.09999999999985551\n",
      "274500 385.0 0.09999999999985551\n",
      "275000 390.0 0.09999999999985551\n",
      "275500 395.0 0.09999999999985551\n",
      "276000 395.0 0.09999999999985551\n",
      "276500 400.0 0.09999999999985551\n",
      "277000 400.0 0.09999999999985551\n",
      "277500 360.0 0.09999999999985551\n",
      "278000 395.0 0.09999999999985551\n",
      "278500 400.0 0.09999999999985551\n",
      "279000 400.0 0.09999999999985551\n",
      "279500 400.0 0.09999999999985551\n",
      "280000 395.0 0.09999999999985551\n",
      "280500 395.0 0.09999999999985551\n",
      "281000 390.0 0.09999999999985551\n",
      "281500 400.0 0.09999999999985551\n",
      "282000 395.0 0.09999999999985551\n",
      "282500 400.0 0.09999999999985551\n",
      "283000 395.0 0.09999999999985551\n",
      "283500 385.0 0.09999999999985551\n",
      "284000 390.0 0.09999999999985551\n",
      "284500 390.0 0.09999999999985551\n",
      "285000 400.0 0.09999999999985551\n",
      "285500 400.0 0.09999999999985551\n",
      "286000 400.0 0.09999999999985551\n",
      "286500 390.0 0.09999999999985551\n",
      "287000 385.0 0.09999999999985551\n",
      "287500 400.0 0.09999999999985551\n",
      "288000 390.0 0.09999999999985551\n",
      "288500 395.0 0.09999999999985551\n",
      "289000 400.0 0.09999999999985551\n",
      "289500 390.0 0.09999999999985551\n",
      "290000 385.0 0.09999999999985551\n",
      "290500 380.0 0.09999999999985551\n",
      "291000 385.0 0.09999999999985551\n",
      "291500 395.0 0.09999999999985551\n",
      "292000 385.0 0.09999999999985551\n",
      "292500 395.0 0.09999999999985551\n",
      "293000 395.0 0.09999999999985551\n",
      "293500 360.0 0.09999999999985551\n",
      "294000 390.0 0.09999999999985551\n",
      "294500 360.0 0.09999999999985551\n",
      "295000 395.0 0.09999999999985551\n",
      "295500 360.0 0.09999999999985551\n",
      "296000 400.0 0.09999999999985551\n",
      "296500 395.0 0.09999999999985551\n",
      "297000 400.0 0.09999999999985551\n",
      "297500 400.0 0.09999999999985551\n",
      "298000 390.0 0.09999999999985551\n",
      "298500 370.0 0.09999999999985551\n",
      "299000 400.0 0.09999999999985551\n",
      "299500 400.0 0.09999999999985551\n",
      "300000 380.0 0.09999999999985551\n",
      "Saved Model\n",
      "300500 385.0 0.09999999999985551\n",
      "301000 360.0 0.09999999999985551\n",
      "301500 375.0 0.09999999999985551\n",
      "302000 400.0 0.09999999999985551\n",
      "302500 390.0 0.09999999999985551\n",
      "303000 395.0 0.09999999999985551\n",
      "303500 385.0 0.09999999999985551\n",
      "304000 400.0 0.09999999999985551\n",
      "304500 390.0 0.09999999999985551\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-eee0c5ea0656>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m                     \u001b[0;31m#Below we perform the Double-DQN update to the target Q-values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                     \u001b[0mQ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmainQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmainQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalarInput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainBatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                     \u001b[0mQ2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtargetQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalarInput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainBatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                     \u001b[0mend_multiplier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainBatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                     \u001b[0mdoubleQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mQ2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mQ1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    935\u001b[0m                 ' to a larger type (e.g. int64).')\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m           \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \"\"\"\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "mainQN = Qnetwork(input_size, actions_size)\n",
    "targetQN = Qnetwork(input_size, actions_size)\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "trainables = tf.trainable_variables()\n",
    "\n",
    "targetOps = updateTargetGraph(trainables,tau)\n",
    "\n",
    "myBuffer = experience_buffer()\n",
    "\n",
    "#Set the rate of random action decrease. \n",
    "e = startE\n",
    "stepDrop = (startE - endE)/anneling_steps\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "jList = []\n",
    "rList = []\n",
    "total_steps = 0\n",
    "\n",
    "#Make a path for our model to be saved in.\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if load_model == True:\n",
    "        print('Loading Model...')\n",
    "        ckpt = tf.train.get_checkpoint_state(path)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "\n",
    "    sess.run(init)\n",
    "    updateTarget(targetOps,sess) #Set the target network to be equal to the primary network.\n",
    "    for i in range(num_episodes):\n",
    "        episodeBuffer = experience_buffer()\n",
    "        #Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        s = processState(s, input_size)\n",
    "        d = False\n",
    "        rAll = 0\n",
    "        j = 0\n",
    "        #The Q-Network\n",
    "        while j < max_epLength: #If the agent takes longer than 200 moves to reach either of the blocks, end the trial.\n",
    "            j+=1\n",
    "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
    "                a = np.random.randint(0, actions_size)\n",
    "            else:\n",
    "                a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n",
    "            s1,r,d,_ = env.step(a)\n",
    "            s1 = processState(s1, input_size)\n",
    "            total_steps += 1\n",
    "            episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5])) #Save the experience to our episode buffer.\n",
    "            \n",
    "            if total_steps > pre_train_steps:\n",
    "                if e > endE:\n",
    "                    e -= stepDrop\n",
    "                \n",
    "                if total_steps % (update_freq) == 0:\n",
    "                    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n",
    "                    #Below we perform the Double-DQN update to the target Q-values\n",
    "                    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
    "                    end_multiplier = -(trainBatch[:,4] - 1)\n",
    "                    doubleQ = Q2[range(batch_size),Q1]\n",
    "                    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n",
    "                    #Update the network with our target values.\n",
    "                    _ = sess.run(mainQN.updateModel, \\\n",
    "                        feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n",
    "                    \n",
    "                    updateTarget(targetOps,sess) #Set the target network to be equal to the primary network.\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            \n",
    "            if d == True:\n",
    "\n",
    "                break\n",
    "        \n",
    "        #Get all experiences from this episode and discount their rewards.\n",
    "        myBuffer.add(episodeBuffer.buffer)\n",
    "        jList.append(j)\n",
    "        rList.append(rAll)\n",
    "        #Periodically save the model. \n",
    "        if i % 1000 == 0:\n",
    "            saver.save(sess,path+'/model-'+str(i)+'.cptk')\n",
    "            print(\"Saved Model\")\n",
    "        if len(rList) % 10 == 0:\n",
    "            print(total_steps,np.mean(rList[-10:]), e)\n",
    "    saver.save(sess,path+'/model-'+str(i)+'.cptk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7eff0318a860>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEjIKdCLiIScAr2ISMj9f0mQbWeip0XfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7eff03f10240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
